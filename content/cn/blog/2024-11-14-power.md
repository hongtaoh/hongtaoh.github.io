---

title: "显著水平、统计功效、一类错误、二类错误"
date: 2024-11-14
author: 郝鸿涛
slug: power-alpha-errors
draft: false
toc: true
tags: 统计

---

>科学研究证明，火星人智商的方差是 `$36$`，我们不知道其平均值 (`$\mu$`)。为了知道 `$\mu$`，科学家随机抽取了 `$16$` 名火星人，测量他们的智商。科学家的假设是 `$H_0: \mu = 100$`，`$H_A: \mu \ne 100$`。

如果把这 16 名火星人的平均智商记为 `$\bar{X}$`，那根据中心极限定理的知识，我们知道其分布为：


```python
import numpy as np 
import matplotlib.pyplot as plt 
import scipy.stats as stats 
```


```python
mu = 100 
sigma = np.sqrt(36)
n = 16 
s = sigma/np.sqrt(n)

xs = np.linspace(mu - 4*s, mu + 4*s, 100)
y = stats.norm.pdf(xs, mu, s)
plt.figure(figsize=(10,6))
plt.plot(
    xs, y, 
    label=r'Distribution of $\bar{X}$', color='blue')
plt.title(r'Distribution of Sample Mean $\bar{X}$ for $n = 16$')
plt.xlabel(r'$\bar{X}$')
plt.ylabel('Probability Density')
plt.axvline(
    mu, color='red', 
    linestyle='--', label=r'$\mu = 100$')
plt.legend()
plt.grid(True)
plt.show()

```


    
![png](/cn/blog/2024-11-14-power_files/2024-11-14-power_3_0.png)
    


## 显著水平、一类错误

如果 `$\alpha = 0.05$`，那么 `$\bar{X}$` 为多少时，我们会拒绝 `$H_0$`？


```python
alpha = 0.05

# norm.ppf() 相当于 R 中的 qnorm() 
# ppf: percent point function; inverse of cdf
lower_bound = stats.norm.ppf(alpha/2, loc=mu, scale = s)
upper_bound = stats.norm.ppf(1-alpha/2, loc = mu, scale = s)
lower_bound, upper_bound
```




    (97.06005402318992, 102.93994597681008)




{{< codeCollapse >}}
plt.figure(figsize=(10, 6))
plt.plot(xs, y, label=r'Distribution of $\bar{X}$', color='blue')
plt.fill_between(xs, y, where=(xs <= lower_bound), color='orange',
                 alpha=0.3, label='Rejection Region (Lower)')
plt.fill_between(xs, y, where=(xs >= upper_bound), color='orange',
                 alpha=0.3, label='Rejection Region (Upper)')
plt.axvline(lower_bound, color='orange', linestyle='--',
            label=f'Lower Critical Value ≈ {lower_bound:.2f}')
plt.axvline(upper_bound, color='orange', linestyle='--',
            label=f'Upper Critical Value ≈ {upper_bound:.2f}')
plt.axvline(mu, color='red', linestyle='--', label=r'$\mu = 100$')
plt.title(r'Distribution of Sample Mean $\bar{X}$ with Rejection Regions')
plt.xlabel(r'$\bar{X}$')
plt.ylabel('Probability Density')
plt.legend()
plt.grid(True)
plt.show()
{{< /codeCollapse >}}


    
![png](/cn/blog/2024-11-14-power_files/2024-11-14-power_6_0.png)
    


上图中的黄色区域被称为「拒绝域」(Rejection Region)。

`$\alpha$` 被称为显著水平，或者叫做「一类错误」(Type one error)。它所表达的意思是，本来 `$H_0$` 是真相，但我们抽到的数据 (黄色区域中的 `$\bar{X}$` 值) 显示 `$H_0$` 为真的话不太可能出现这样的 `$\bar{X}$`，所以我们（错误地）拒绝。

## 统计功效和二类错误

我们来看另外一种情况：`$H_0$` 不成立，`$H_A：\mu_{A} = 105$` 为真。

`$H_A$` 如果成立，`$\bar{X}$` 的分布是：


```python
mu = 105
sigma = np.sqrt(36)
n = 16 
s = sigma/np.sqrt(n)

xs = np.linspace(mu - 4*s, mu + 4*s, 100)
y = stats.norm.pdf(xs, mu, s)
plt.figure(figsize=(10,6))
plt.plot(
    xs, y, 
    label=r'Distribution of $\bar{X}$', color='blue')
plt.title(r'Distribution of Sample Mean $\bar{X}$ for $n = 16$, Given $H_A$ Being True')
plt.xlabel(r'$\bar{X}$')
plt.ylabel('Probability Density')
plt.axvline(
    mu, color='red', 
    linestyle='--', label=r'$\mu = 100$')
plt.legend()
plt.grid(True)
plt.show()
```


    
![png](/cn/blog/2024-11-14-power_files/2024-11-14-power_8_0.png)
    


那当 `$H_A$` 成立时，`$\bar{X}$` 落在上图黄色区域，也就是拒绝域，的概率是多大？


```python
lower_region_area = stats.norm.cdf(lower_bound, loc=mu, scale = s)
upper_region_area = 1-stats.norm.cdf(upper_bound, loc=mu, scale = s)
lower_region_area + upper_region_area
```




    0.9151812833018267



我们看到概率大概是 `$91.5\%$`，这被称为「统计功效」(Power)，也就是说当 `$H_0$` 为假、`$H_A$` 为真时，我们拒绝 `$H_0$` 的概率。

那当 `$H_0$` 为假、`$H_A$` 为真时，我们也可能会接受 `$H_0$`，这种情况下我们犯了「二类错误」(Type Two Error)。很明显，Type Two Error = 1 - Power。因为 `$H_0$` 为假、`$H_A$` 为真时，我们要么接受 `$H_0$`，要么拒绝，不可能有第三种情况。
