{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "0df02681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# http://www.adeveloperdiary.com/data-science/deep-learning/neural-network-with-softmax-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "6fb9fd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(file):\n",
    "    df = pd.read_csv(file)\n",
    "    x = (df.iloc[:, 1:]/255.0).to_numpy()\n",
    "    y = df.iloc[:, 0].to_numpy()\n",
    "    '''one hot encoding for y\n",
    "    y will be the dimension of (n, k) where n is the number of training instances\n",
    "    and k is the number of classes (0-9)\n",
    "    '''\n",
    "    y = pd.get_dummies(y).to_numpy()\n",
    "    return (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a4af0524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x train, y train\n",
    "x, y = data_loader('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a0b1c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = data_loader('mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1495d8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9999, 784), (9999, 10))"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a7074a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((59999, 784), (59999, 10))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a8a38fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, ..., 5, 6, 8])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_labels = np.where(y == 1)[1]\n",
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c9cc4bec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59999"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argmax(y, axis=1)  == true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "eca13f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of sigmoid function\n",
    "# https://medium.com/@DannyDenenberg/derivative-of-the-sigmoid-function-774446dfa462\n",
    "\n",
    "## How sigmoid and softmax were derived:\n",
    "# https://towardsdatascience.com/sigmoid-and-softmax-functions-in-5-minutes-f516c80ea1f9\n",
    "\n",
    "## softmax and cross entropy derivative\n",
    "# https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/\n",
    "\n",
    "## number of units in the hidden layer\n",
    "h = 28\n",
    "\n",
    "# number of units in the input layer, i.e., 784\n",
    "m = x.shape[1]\n",
    "\n",
    "# number of classes, i.e., 10 (0-9)\n",
    "k = y.shape[1]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x + 10e-10))\n",
    "\n",
    "def sigmoid_derivative(o):\n",
    "    return sigmoid(o) * (1 - sigmoid(o))\n",
    "\n",
    "def softmax(x):\n",
    "    expz = np.exp(x - x.max())\n",
    "    return expz / np.sum(expz, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e95bc1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59999"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "516fd410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 784)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, :].reshape(1, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2fd762b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0, :].reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "3fb5dded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 784)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0:30, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5f6e466f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0:20, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "c5714715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05, 0.2 , 0.1 , 0.15, 0.15, 0.05, 0.1 , 0.05, 0.05, 0.1 ])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y[0:20, :], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "78902f8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(y[0:20, :], axis = 0).reshape(-1, 1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3737419",
   "metadata": {},
   "source": [
    "`*` is element wise multiplication. `@` is matrix multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ad3b3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def nnet(train_x, train_y, alpha, num_epochs, num_train, batch_size, true_labels):\n",
    "#     # initiate parameters\n",
    "#     # w1: h * 784\n",
    "#     w1 = np.random.uniform(low=-1, high = 1, size = (h, m))\n",
    "#     # w2: k * h\n",
    "#     w2 = np.random.uniform(low=-1, high = 1, size = (k, h))\n",
    "#     # b1: h * 1\n",
    "#     b1 = np.random.uniform(low=-1, high = 1, size = (h, 1))\n",
    "#     # b2: k * 1\n",
    "#     b2 = np.random.uniform(low=-1, high = 1, size = (k, 1))\n",
    "    \n",
    "#     # set a large number as the initial cost to be compared with in the 1st iteration\n",
    "#     loss_previous = 10e10\n",
    "    \n",
    "#     for epoch in range(1, num_epochs + 1):\n",
    "#         # shuffle the dataset\n",
    "#         train_index = np.arange(num_train)\n",
    "#         np.random.shuffle(train_index)\n",
    "\n",
    "#         # https://stackoverflow.com/a/48702959\n",
    "#         for index in range(0, len(train_x), batch_size):\n",
    "#             batch_x =train_x[index:min(index+batch_size,len(train_x)),:]\n",
    "#             batch_y =train_y[index:min(index+batch_size,len(train_y)),:]\n",
    "            \n",
    "#             z1 = batch_x @ w1.T + b1.T\n",
    "#             # a1 will be of the dimensionn of N * h\n",
    "#             a1 = sigmoid(z1)\n",
    "            \n",
    "# #             print(a1.shape)\n",
    "            \n",
    "#             z2 = a1 @ w2.T + b2.T\n",
    "#             # a2 will be of the dimension of N * k\n",
    "#             a2 = softmax(z2)\n",
    "            \n",
    "# #             print(a2.shape)\n",
    "            \n",
    "#             # N * k\n",
    "#             dcdb2 = a2 - batch_y\n",
    "            \n",
    "#             # k * h\n",
    "#             dcdw2 = dcdb2.T @ a1\n",
    "            \n",
    "#             # N * h\n",
    "#             dcdb1 = ((a2 - batch_y) @ w2) *  a1 * (1-a1)\n",
    "            \n",
    "# #             print(dcdb1.T.shape)\n",
    "# #             print(train_x[i, :].shape)\n",
    "            \n",
    "#             # h * m\n",
    "#             dcdw1 = dcdb1.T @ batch_x\n",
    "                     \n",
    "#             # update w1, b1, w2, b2\n",
    "#             w1 = w1 - alpha*dcdw1\n",
    "#             b1 = b1 - alpha*np.mean(dcdb1, axis = 0).reshape(-1, 1)\n",
    "#             w2 = w2- alpha*dcdw2\n",
    "#             b2 = b2 - alpha*np.mean(dcdb2, axis = 0).reshape(-1, 1)\n",
    "                     \n",
    "#         # the output of the hidden layer will be a num_train * h matrix\n",
    "#         out_h = sigmoid(train_x @ w1.T + b1.T)\n",
    "#         # the output of the output layer will be a num_train * k matrix\n",
    "#         out_o = softmax(out_h @ w2.T + b2.T)\n",
    "                     \n",
    "#         predicted_labels = np.argmax(out_o, axis=1)\n",
    "        \n",
    "#         loss = -np.sum(y * np.log(out_o + 10e-10))\n",
    "#         loss_reduction = loss_previous - loss\n",
    "#         loss_previous = loss\n",
    "#         correct = sum(true_labels == predicted_labels)\n",
    "#         accuracy = (correct / num_train)\n",
    "#         print('epoch = ', epoch, ' loss = {:.7}'.format(loss), \\\n",
    "#               ' loss reduction = {:.7}'.format(loss_reduction), \\\n",
    "#               ' correctly classified = {:.4%}'.format(accuracy))\n",
    "        \n",
    "#     return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "771ce22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet(train_x, train_y, alpha, num_epochs, num_train, true_labels):\n",
    "    # initiate parameters\n",
    "    # w1: h * 784\n",
    "    w1 = np.random.uniform(low=-1, high = 1, size = (h, m))\n",
    "    # w2: 10 * h\n",
    "    w2 = np.random.uniform(low=-1, high = 1, size = (k, h))\n",
    "    # b1: h * 1\n",
    "    b1 = np.random.uniform(low=-1, high = 1, size = (h, 1))\n",
    "    # b2: 10 * 1\n",
    "    b2 = np.random.uniform(low=-1, high = 1, size = (k, 1))\n",
    "    \n",
    "    # set a large number as the initial cost to be compared with in the 1st iteration\n",
    "    loss_previous = 10e10\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # shuffle the dataset\n",
    "        train_index = np.arange(num_train)\n",
    "        np.random.shuffle(train_index)\n",
    "        \n",
    "        for i in train_index:\n",
    "            # z1 will be of the dimensionn of h * 1\n",
    "            z1 = w1 @ train_x[i, :].reshape(-1, 1) + b1\n",
    "            \n",
    "            # a1 will be of the dimensionn of h * 1\n",
    "            a1 = sigmoid(z1)\n",
    "            \n",
    "            # z2 will be of the dimension of 10 * 1\n",
    "            z2 = w2 @ a1 + b2\n",
    "            \n",
    "            # a2 will be of the dimension of 10 * 1\n",
    "            a2 = softmax(z2)\n",
    "            \n",
    "            # 10 * 1\n",
    "            dcdb2 = a2 - train_y[i, :].reshape(-1, 1)\n",
    "            \n",
    "            # 10 * h\n",
    "            dcdw2 = dcdb2 @ a1.T\n",
    "            \n",
    "            # h * 1 \n",
    "            dcdb1 = (w2.T @ (a2 - train_y[i, :].reshape(-1, 1))) *  a1 * (1-a1)\n",
    "            \n",
    "            # h * 784 \n",
    "            dcdw1 = dcdb1 @ (train_x[i, :].reshape(-1, 1)).T\n",
    "                     \n",
    "            # update w1, b1, w2, b2\n",
    "            w1 = w1 - alpha*dcdw1\n",
    "            b1 = b1 - alpha*dcdb1\n",
    "            w2 = w2- alpha*dcdw2\n",
    "            b2 = b2 - alpha*dcdb2\n",
    "                     \n",
    "        # the output of the hidden layer will be a num_train * h matrix\n",
    "        out_h = sigmoid(train_x @ w1.T + b1.T)\n",
    "        # the output of the output layer will be a num_train * k matrix\n",
    "        out_o = softmax(out_h @ w2.T + b2.T)\n",
    "                     \n",
    "        predicted_labels = np.argmax(out_o, axis=1)\n",
    "        \n",
    "        loss = -np.sum(y * np.log(out_o + 10e-10))\n",
    "        loss_reduction = loss_previous - loss\n",
    "        loss_previous = loss\n",
    "        correct = sum(true_labels == predicted_labels)\n",
    "        accuracy = (correct / num_train)\n",
    "        print('epoch = ', epoch, ' loss = {:.7}'.format(loss), \\\n",
    "              ' loss reduction = {:.7}'.format(loss_reduction), \\\n",
    "              ' correctly classified = {:.4%}'.format(accuracy))\n",
    "        \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3d3e4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .5\n",
    "num_epochs = 5\n",
    "# batch_size = 32\n",
    "num_train = len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "b93682b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 688574.6  loss reduction = 9.999931e+10  correctly classified = 73.0012%\n",
      "epoch =  2  loss = 691671.8  loss reduction = -3097.243  correctly classified = 70.8262%\n",
      "epoch =  3  loss = 696048.3  loss reduction = -4376.461  correctly classified = 68.6878%\n",
      "epoch =  4  loss = 715785.6  loss reduction = -19737.33  correctly classified = 74.3546%\n",
      "epoch =  5  loss = 711111.5  loss reduction = 4674.141  correctly classified = 72.6712%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bebed9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(x_test, y_test, w1, b1, w2, b2):\n",
    "    # the output of the hidden layer will be a num_train * h matrix\n",
    "    out_h = sigmoid(x_test @ w1.T + b1.T)\n",
    "    # the output of the output layer will be a num_train * k matrix\n",
    "    out_o = softmax(out_h @ w2.T + b2.T)\n",
    "\n",
    "    true_labels = np.where(y_test == 1)[1]\n",
    "    predicted_labels = np.argmax(out_o, axis=1)\n",
    "    correct = sum(true_labels == predicted_labels)\n",
    "    accuracy = (correct / len(x_test))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "1ca71a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7317731773177317"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.5, num_epochs = 5\n",
    "acc01 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ac2617d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2682268226822683"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d577890a",
   "metadata": {},
   "source": [
    "## Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "17bf8e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .3\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "615ea063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 641309.4  loss reduction = 9.999936e+10  correctly classified = 84.9847%\n",
      "epoch =  2  loss = 686734.1  loss reduction = -45424.72  correctly classified = 80.6680%\n",
      "epoch =  3  loss = 670585.7  loss reduction = 16148.39  correctly classified = 77.5096%\n",
      "epoch =  4  loss = 660587.2  loss reduction = 9998.515  correctly classified = 83.9014%\n",
      "epoch =  5  loss = 663142.2  loss reduction = -2555.025  correctly classified = 86.9714%\n",
      "epoch =  6  loss = 680786.6  loss reduction = -17644.39  correctly classified = 81.0947%\n",
      "epoch =  7  loss = 685813.0  loss reduction = -5026.384  correctly classified = 83.3781%\n",
      "epoch =  8  loss = 680576.0  loss reduction = 5236.961  correctly classified = 85.7464%\n",
      "epoch =  9  loss = 672710.2  loss reduction = 7865.797  correctly classified = 86.2031%\n",
      "epoch =  10  loss = 700287.0  loss reduction = -27576.74  correctly classified = 78.0146%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "8d65e4b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7765776577657766"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.3, num_epochs = 10\n",
    "acc02 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3073609d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22342234223422341"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4b9f8",
   "metadata": {},
   "source": [
    "## Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "77c2ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .1\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6921be0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 614265.2  loss reduction = 9.999939e+10  correctly classified = 90.2932%\n",
      "epoch =  2  loss = 623161.1  loss reduction = -8895.854  correctly classified = 91.1732%\n",
      "epoch =  3  loss = 645744.5  loss reduction = -22583.48  correctly classified = 89.4482%\n",
      "epoch =  4  loss = 650997.8  loss reduction = -5253.284  correctly classified = 90.9765%\n",
      "epoch =  5  loss = 657714.5  loss reduction = -6716.704  correctly classified = 90.9665%\n",
      "epoch =  6  loss = 663668.8  loss reduction = -5954.312  correctly classified = 91.4215%\n",
      "epoch =  7  loss = 666588.2  loss reduction = -2919.38  correctly classified = 91.9599%\n",
      "epoch =  8  loss = 669431.0  loss reduction = -2842.817  correctly classified = 91.9815%\n",
      "epoch =  9  loss = 684651.9  loss reduction = -15220.83  correctly classified = 91.6282%\n",
      "epoch =  10  loss = 690363.0  loss reduction = -5711.182  correctly classified = 91.0682%\n",
      "epoch =  11  loss = 685009.8  loss reduction = 5353.28  correctly classified = 90.8065%\n",
      "epoch =  12  loss = 687552.2  loss reduction = -2542.457  correctly classified = 92.3432%\n",
      "epoch =  13  loss = 698868.5  loss reduction = -11316.24  correctly classified = 90.6082%\n",
      "epoch =  14  loss = 704411.9  loss reduction = -5543.474  correctly classified = 91.0715%\n",
      "epoch =  15  loss = 701649.1  loss reduction = 2762.801  correctly classified = 91.4465%\n",
      "epoch =  16  loss = 717919.4  loss reduction = -16270.27  correctly classified = 91.0549%\n",
      "epoch =  17  loss = 713912.0  loss reduction = 4007.402  correctly classified = 88.6115%\n",
      "epoch =  18  loss = 716915.8  loss reduction = -3003.777  correctly classified = 89.7132%\n",
      "epoch =  19  loss = 717934.1  loss reduction = -1018.318  correctly classified = 91.7015%\n",
      "epoch =  20  loss = 731659.8  loss reduction = -13725.71  correctly classified = 91.4615%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "098678f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8987898789878987"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.1, num_epochs = 20\n",
    "acc03 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f91fcb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10121012101210125"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "6ef8be16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([5, 10, 20], [acc01, acc02, acc03])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.savefig('lc01.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f128a",
   "metadata": {},
   "source": [
    "## Using all zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "c01567bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nnet(train_x, train_y, alpha, num_epochs, num_train, true_labels):\n",
    "    # initiate parameters\n",
    "    # w1: h * 784\n",
    "    w1 = np.zeros((h, m))\n",
    "    # w2: 10 * h\n",
    "    w2 = np.zeros((k, h))\n",
    "    # b1: h * 1\n",
    "    b1 = np.zeros((h, 1))\n",
    "    # b2: 10 * 1\n",
    "    b2 = np.zeros((k, 1))\n",
    "    \n",
    "    # set a large number as the initial cost to be compared with in the 1st iteration\n",
    "    loss_previous = 10e10\n",
    "    \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # shuffle the dataset\n",
    "        train_index = np.arange(num_train)\n",
    "        np.random.shuffle(train_index)\n",
    "        \n",
    "        for i in train_index:\n",
    "            z1 = w1 @ train_x[i, :].reshape(-1, 1) + b1\n",
    "            # a1 will be of the dimensionn of h * 1\n",
    "            a1 = sigmoid(z1)\n",
    "            \n",
    "            z2 = w2 @ a1 + b2\n",
    "            # a2 will be of the dimension of 10 * 1\n",
    "            a2 = softmax(z2)\n",
    "            \n",
    "            # 10 * 1\n",
    "            dcdb2 = a2 - train_y[i, :].reshape(-1, 1)\n",
    "            \n",
    "            # 10 * h\n",
    "            dcdw2 = dcdb2 @ a1.T\n",
    "            \n",
    "            # h * 1 \n",
    "            dcdb1 = (w2.T @ (a2 - train_y[i, :].reshape(-1, 1))) *  a1 * (1-a1)\n",
    "            \n",
    "            # h * 784 \n",
    "            dcdw1 = dcdb1 @ (train_x[i, :].reshape(-1, 1)).T\n",
    "                     \n",
    "            # update w1, b1, w2, b2\n",
    "            w1 = w1 - alpha*dcdw1\n",
    "            b1 = b1 - alpha*dcdb1\n",
    "            w2 = w2- alpha*dcdw2\n",
    "            b2 = b2 - alpha*dcdb2\n",
    "                     \n",
    "        # the output of the hidden layer will be a num_train * h matrix\n",
    "        out_h = sigmoid(train_x @ w1.T + b1.T)\n",
    "        # the output of the output layer will be a num_train * k matrix\n",
    "        out_o = softmax(out_h @ w2.T + b2.T)\n",
    "                     \n",
    "        predicted_labels = np.argmax(out_o, axis=1)\n",
    "        \n",
    "        loss = -np.sum(y * np.log(out_o + 10e-10))\n",
    "        loss_reduction = loss_previous - loss\n",
    "        loss_previous = loss\n",
    "        correct = sum(true_labels == predicted_labels)\n",
    "        accuracy = (correct / num_train)\n",
    "        print('epoch = ', epoch, ' loss = {:.7}'.format(loss), \\\n",
    "              ' loss reduction = {:.7}'.format(loss_reduction), \\\n",
    "              ' correctly classified = {:.4%}'.format(accuracy))\n",
    "        \n",
    "    return w1, b1, w2, b2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6f7a2",
   "metadata": {},
   "source": [
    "### Round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "3cdd0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .5\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "0e2ba29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 794830.4  loss reduction = 9.999921e+10  correctly classified = 13.5636%\n",
      "epoch =  2  loss = 805828.1  loss reduction = -10997.67  correctly classified = 12.4319%\n",
      "epoch =  3  loss = 830751.7  loss reduction = -24923.59  correctly classified = 15.8186%\n",
      "epoch =  4  loss = 867434.7  loss reduction = -36683.02  correctly classified = 15.9953%\n",
      "epoch =  5  loss = 839142.2  loss reduction = 28292.47  correctly classified = 14.7269%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "52d96e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15011501150115011"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.5, num_epochs = 5\n",
    "acc011 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc011"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "88656a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8498849884988499"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc011"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc97f6",
   "metadata": {},
   "source": [
    "### Round 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "280b6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .3\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8d151b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 911809.0  loss reduction = 9.999909e+10  correctly classified = 13.2586%\n",
      "epoch =  2  loss = 964698.2  loss reduction = -52889.2  correctly classified = 12.4552%\n",
      "epoch =  3  loss = 987338.2  loss reduction = -22640.0  correctly classified = 10.1035%\n",
      "epoch =  4  loss = 1.007491e+06  loss reduction = -20152.55  correctly classified = 10.3285%\n",
      "epoch =  5  loss = 983613.9  loss reduction = 23876.81  correctly classified = 11.5485%\n",
      "epoch =  6  loss = 999315.4  loss reduction = -15701.49  correctly classified = 9.9802%\n",
      "epoch =  7  loss = 940512.2  loss reduction = 58803.18  correctly classified = 11.2919%\n",
      "epoch =  8  loss = 908557.9  loss reduction = 31954.37  correctly classified = 13.6002%\n",
      "epoch =  9  loss = 912310.4  loss reduction = -3752.515  correctly classified = 12.7935%\n",
      "epoch =  10  loss = 914383.1  loss reduction = -2072.708  correctly classified = 12.6552%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "449707bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12841284128412842"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.3, num_epochs = 10\n",
    "acc022 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "afe2b16d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715871587158716"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c361421d",
   "metadata": {},
   "source": [
    "### Round 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "26c3d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .1\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d987e0ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  1  loss = 829027.0  loss reduction = 9.999917e+10  correctly classified = 13.8636%\n",
      "epoch =  2  loss = 913736.3  loss reduction = -84709.33  correctly classified = 12.2019%\n",
      "epoch =  3  loss = 932422.7  loss reduction = -18686.42  correctly classified = 12.2302%\n",
      "epoch =  4  loss = 967144.9  loss reduction = -34722.18  correctly classified = 12.6619%\n",
      "epoch =  5  loss = 989439.5  loss reduction = -22294.57  correctly classified = 13.1452%\n",
      "epoch =  6  loss = 997981.4  loss reduction = -8541.925  correctly classified = 12.4552%\n",
      "epoch =  7  loss = 997861.9  loss reduction = 119.4672  correctly classified = 13.7552%\n",
      "epoch =  8  loss = 1.008604e+06  loss reduction = -10742.01  correctly classified = 13.1002%\n",
      "epoch =  9  loss = 1.003792e+06  loss reduction = 4812.392  correctly classified = 14.0569%\n",
      "epoch =  10  loss = 1.020578e+06  loss reduction = -16786.8  correctly classified = 13.8469%\n",
      "epoch =  11  loss = 1.023858e+06  loss reduction = -3279.963  correctly classified = 13.6786%\n",
      "epoch =  12  loss = 1.026934e+06  loss reduction = -3075.944  correctly classified = 12.6469%\n",
      "epoch =  13  loss = 1.017064e+06  loss reduction = 9870.686  correctly classified = 15.1503%\n",
      "epoch =  14  loss = 1.045098e+06  loss reduction = -28034.75  correctly classified = 13.5102%\n",
      "epoch =  15  loss = 1.033583e+06  loss reduction = 11515.76  correctly classified = 12.7219%\n",
      "epoch =  16  loss = 1.038164e+06  loss reduction = -4581.01  correctly classified = 13.5486%\n",
      "epoch =  17  loss = 1.042809e+06  loss reduction = -4645.097  correctly classified = 12.5269%\n",
      "epoch =  18  loss = 1.042473e+06  loss reduction = 336.0035  correctly classified = 12.2552%\n",
      "epoch =  19  loss = 1.037464e+06  loss reduction = 5008.563  correctly classified = 14.0069%\n",
      "epoch =  20  loss = 1.046982e+06  loss reduction = -9517.933  correctly classified = 14.0286%\n"
     ]
    }
   ],
   "source": [
    "w1, b1, w2, b2 = nnet(x, y, alpha, num_epochs, num_train, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "4e029e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1407140714071407"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy when alpha = 0.1, num_epochs = 20\n",
    "acc033 = compute_accuracy(x_test, y_test, w1, b1, w2, b2)\n",
    "acc033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4f8769b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8592859285928593"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 - acc033"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9395b864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter([5, 10, 20], [acc011, acc022, acc033])\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Learning Curve')\n",
    "plt.savefig('lc02.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff33252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
