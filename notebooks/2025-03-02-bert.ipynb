{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "title: \"一文搞懂 Bert 模型、向量表示、向量搜索、API\"\n",
    "date: 2025-03-02\n",
    "author: 郝鸿涛\n",
    "slug: bert\n",
    "draft: false\n",
    "toc: true\n",
    "tags: ML\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们现在有一万个电影的文字描述，如何根据用户的搜索，推荐给用户最相关的几个电影？比如，用户输入「NASA 努力救一个困在火星的宇航员」，那我们肯定会导出《火星救援》。如何实现呢？\n",
    "\n",
    "办法是，假设我们有一个神奇的工具，你可以把它想象成一张网。任何一串文字通过它之后，都会变成一个高维空间里的一个向量，也就是高维空间里的一个坐标。然后我们让这一万条电影的文字描述经过这张网，我们得到一万个坐标。用户输入搜索，我们让这个搜索也经过这张网，得到一个坐标。最后的结果，我们计算这个搜索对应的坐标与每一个电影坐标的余弦相似度 (Cosine Similarity)，然后找到结果最大的几个，就是我们的搜索结果。\n",
    "\n",
    "这里涉及到一个问题。如果我们把每串文字经过网后的结果看成是一个坐标，那么寻找相似的点，可以用[欧几里得距离](https://zh.wikipedia.org/zh-hans/%E6%AC%A7%E5%87%A0%E9%87%8C%E5%BE%97%E8%B7%9D%E7%A6%BB)。如果我们把每个结果看成是一个向量，那么需要用余弦相似度。我们这里把结果看成是向量比较合适。为什么？我现在还没有办法解释清楚。\n",
    "\n",
    "这张神奇的网是「向量表示 (Embedding)」。比较知名的是 Bert，它比较大，我们这里用 Sentence Transformers。更神奇的是，如果我们用多语言的模型，比如 `paraphrase-multilingual-mpnet-base-v2`，那即使我们的训练数据是英文的，我们也可以用中文搜索。不过，多语言模型也比较大，我们这里不用。我们用比较小的 `all-MiniLM-L6-v2`。\n",
    "\n",
    "另外，我们用 [FAISS](https://pypi.org/project/faiss-cpu/) (Facebook AI Similarity Search) 计算余弦相似度，因为这比较快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据\n",
    "\n",
    "数据下载地址：[https://hongtaoh.com/files/tmdb-movies.csv](/../files/tmdb-movies.csv)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10866, 21)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../static/files/tmdb-movies.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据很大，我只选取几个关键的列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135397</td>\n",
       "      <td>tt0369610</td>\n",
       "      <td>1513528810</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Twenty-two years after the events of Jurassic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76341</td>\n",
       "      <td>tt1392190</td>\n",
       "      <td>378436354</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262500</td>\n",
       "      <td>tt2908446</td>\n",
       "      <td>295238201</td>\n",
       "      <td>Insurgent</td>\n",
       "      <td>Beatrice Prior must confront her inner demons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140607</td>\n",
       "      <td>tt2488496</td>\n",
       "      <td>2068178225</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168259</td>\n",
       "      <td>tt2820852</td>\n",
       "      <td>1506249360</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Deckard Shaw seeks revenge against Dominic Tor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    imdb_id     revenue                original_title  \\\n",
       "0  135397  tt0369610  1513528810                Jurassic World   \n",
       "1   76341  tt1392190   378436354            Mad Max: Fury Road   \n",
       "2  262500  tt2908446   295238201                     Insurgent   \n",
       "3  140607  tt2488496  2068178225  Star Wars: The Force Awakens   \n",
       "4  168259  tt2820852  1506249360                     Furious 7   \n",
       "\n",
       "                                            overview  \n",
       "0  Twenty-two years after the events of Jurassic ...  \n",
       "1  An apocalyptic story set in the furthest reach...  \n",
       "2  Beatrice Prior must confront her inner demons ...  \n",
       "3  Thirty years after defeating the Galactic Empi...  \n",
       "4  Deckard Shaw seeks revenge against Dominic Tor...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:5, [0, 1, 4, 5, 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们看下最关键的 `imdb_id`、`original_title` 和 `overview` 有没有缺失："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>355131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Sense8: Creating the World</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>287663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Star Wars Rebels: Spark of Rebellion</td>\n",
       "      <td>A Long Time Ago In A Galaxy Far, Far Awayâ€¦ A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>15257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Hulk vs. Wolverine</td>\n",
       "      <td>Department H sends in Wolverine to track down ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>101907</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Hulk vs. Thor</td>\n",
       "      <td>For ages, Odin has protected his kingdom of As...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2370</th>\n",
       "      <td>127717</td>\n",
       "      <td>tt1525359</td>\n",
       "      <td>0</td>\n",
       "      <td>Freshman Father</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>45644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Opeth: In Live Concert At The Royal Albert Hall</td>\n",
       "      <td>As part of the ongoing celebration of their 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3722</th>\n",
       "      <td>85993</td>\n",
       "      <td>tt1680105</td>\n",
       "      <td>0</td>\n",
       "      <td>Baciato dalla fortuna</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>58253</td>\n",
       "      <td>tt1588335</td>\n",
       "      <td>0</td>\n",
       "      <td>Toi, moi, les autres</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>369145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who: The Snowmen</td>\n",
       "      <td>Christmas Eve, 1892, and the falling snow is t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4872</th>\n",
       "      <td>269177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Party Bercy</td>\n",
       "      <td>Florence Foresti is offered Bercy tribute to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>279954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Portal: Survive!</td>\n",
       "      <td>A short, live action fan film by Collin and Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>50127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fallen: The Journey</td>\n",
       "      <td>A year later, Aaron is still traveling around ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7809</th>\n",
       "      <td>50128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Fallen: The Destiny</td>\n",
       "      <td>Aaron and Azazel defeat the Powers, and force ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    imdb_id  revenue  \\\n",
       "548   355131        NaN        0   \n",
       "997   287663        NaN        0   \n",
       "1528   15257        NaN        0   \n",
       "1750  101907        NaN        0   \n",
       "2370  127717  tt1525359        0   \n",
       "2401   45644        NaN        0   \n",
       "3722   85993  tt1680105        0   \n",
       "3794   58253  tt1588335        0   \n",
       "4797  369145        NaN        0   \n",
       "4872  269177        NaN        0   \n",
       "6071  279954        NaN        0   \n",
       "7527   50127        NaN        0   \n",
       "7809   50128        NaN        0   \n",
       "\n",
       "                                       original_title  \\\n",
       "548                        Sense8: Creating the World   \n",
       "997              Star Wars Rebels: Spark of Rebellion   \n",
       "1528                               Hulk vs. Wolverine   \n",
       "1750                                    Hulk vs. Thor   \n",
       "2370                                  Freshman Father   \n",
       "2401  Opeth: In Live Concert At The Royal Albert Hall   \n",
       "3722                            Baciato dalla fortuna   \n",
       "3794                             Toi, moi, les autres   \n",
       "4797                          Doctor Who: The Snowmen   \n",
       "4872                                      Party Bercy   \n",
       "6071                                 Portal: Survive!   \n",
       "7527                              Fallen: The Journey   \n",
       "7809                              Fallen: The Destiny   \n",
       "\n",
       "                                               overview  \n",
       "548                                                 NaN  \n",
       "997   A Long Time Ago In A Galaxy Far, Far Awayâ€¦ A...  \n",
       "1528  Department H sends in Wolverine to track down ...  \n",
       "1750  For ages, Odin has protected his kingdom of As...  \n",
       "2370                                                NaN  \n",
       "2401  As part of the ongoing celebration of their 20...  \n",
       "3722                                                NaN  \n",
       "3794                                                NaN  \n",
       "4797  Christmas Eve, 1892, and the falling snow is t...  \n",
       "4872  Florence Foresti is offered Bercy tribute to a...  \n",
       "6071  A short, live action fan film by Collin and Co...  \n",
       "7527  A year later, Aaron is still traveling around ...  \n",
       "7809  Aaron and Azazel defeat the Powers, and force ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na = df[df[['imdb_id', 'original_title', 'overview']].isna().any(axis = 1)]\n",
    "df_na.iloc[:, [0, 1, 4, 5, 11]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "把这些去掉："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['imdb_id', 'original_title', 'overview'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们只需要用到这两列\n",
    "movie_ids = df.imdb_id.tolist()\n",
    "movie_overviews = df.overview.tolist()\n",
    "\n",
    "#create dictionaries\n",
    "imbdId2Title = dict(zip(df.imdb_id, df.original_title))\n",
    "imbdId2Overview = dict(zip(df.imdb_id, df.overview))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongtaoh/anaconda3/envs/bayes/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "from typing import List, Dict, Tuple\n",
    "import faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_embeddings(\n",
    "    movie_ids:List[str], \n",
    "    movie_overviews:List[str], \n",
    "    model: SentenceTransformer,\n",
    "    batch_size: int = 32, \n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates normalized embeddings for movie overviews.\n",
    "\n",
    "    Args:\n",
    "        movie_ids: List of movie IDs.\n",
    "        movie_overviews: List of movie overviews.\n",
    "        model: Embedding model (e.g., SentenceTransformer).\n",
    "        batch_size: Batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping movie IDs to normalized embeddings.\n",
    "    \"\"\"\n",
    "    if len(movie_ids) != len(movie_overviews):\n",
    "        raise ValueError(\"movie_ids and movie_overviews must have the same length.\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(movie_ids), batch_size):\n",
    "        batch_movies = movie_overviews[i:i+batch_size]\n",
    "        try:\n",
    "            batch_embeddings = model.encode(batch_movies)\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding batch {i}: {e}\")\n",
    "            raise\n",
    "    try:\n",
    "        all_embeddings_np = np.array(all_embeddings) #added numpy array conversion.\n",
    "        normalized_embeddings = normalize(all_embeddings_np, axis=1, norm='l2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing embeddings: {e}\")\n",
    "        raise\n",
    "\n",
    "    movie_embeddings = dict(zip(movie_ids, normalized_embeddings))\n",
    "    return movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = get_movie_embeddings(movie_ids, movie_overviews, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_faiss_index(\n",
    "    movie_embeddings: Dict[str, np.ndarray]) -> Tuple[faiss.Index, List[str]]:\n",
    "    \"\"\"\n",
    "    Prepares a FAISS index from movie embeddings.\n",
    "    \n",
    "    Args:\n",
    "        movie_embeddings: Dictionary of movie IDs to normalized embeddings.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (FAISS index, ordered list of movie IDs)\n",
    "    \"\"\"\n",
    "    movie_ids = list(movie_embeddings.keys())\n",
    "    embeddings = np.array([movie_embeddings[mid] for mid in movie_ids])\n",
    "\n",
    "    #create and populate the index\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    return index, movie_ids\n",
    "\n",
    "def search_movies(\n",
    "    faiss_index: faiss.Index,\n",
    "    movie_ids: List[str],\n",
    "    user_query: str,\n",
    "    model: SentenceTransformer,\n",
    "    k: int = 10,\n",
    ") -> Tuple[List[str], List[float]]:\n",
    "    \"\"\"\n",
    "    Searches movies based on a user query using Faiss and cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        faiss_index: Pre-built FAISS index\n",
    "        movie_ids: Ordered list of movie IDs that corresponds to the index\n",
    "        user_query: The user's search query.\n",
    "        model: SentenceTransformer model.\n",
    "        k: Number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        Tuple, top K movie titles and their associated cosine similarity scores\n",
    "    \"\"\"\n",
    "    #embed and normalize the user query\n",
    "    query_embedding = model.encode([user_query])\n",
    "    normalized_query_embedding = normalize(query_embedding, axis = 1, norm = 'l2')\n",
    "\n",
    "    #search the index\n",
    "    similarities, indices = faiss_index.search(normalized_query_embedding, k)\n",
    "\n",
    "    #retrieve movie ids and similarity scores\n",
    "    top_k_ids = [movie_ids[i] for i in indices[0]]\n",
    "    top_k_titles = [imbdId2Title[x] for x in top_k_ids]\n",
    "    top_k_scores = similarities[0]\n",
    "    return top_k_titles, top_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "faiss_index, movie_ids = prepare_faiss_index(movie_embeddings)\n",
    "user_query = \"NASA tried to rescue an astronaut stranded on Mars.\"\n",
    "results = search_movies(\n",
    "    faiss_index,\n",
    "    movie_ids,\n",
    "    user_query,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mission to Mars',\n",
       "  'Red Planet',\n",
       "  'Robinson Crusoe on Mars',\n",
       "  'The Martian',\n",
       "  'Capricorn One',\n",
       "  'My Favorite Martian',\n",
       "  'The Last Days on Mars',\n",
       "  'Infini',\n",
       "  '(T)Raumschiff Surprise - Periode 1',\n",
       "  'My Stepmother is an Alien'],\n",
       " array([0.6767248 , 0.6620594 , 0.651513  , 0.55047977, 0.5192548 ,\n",
       "        0.49691725, 0.4924257 , 0.46683484, 0.46024293, 0.44739127],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果正确。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 走向云端\n",
    "\n",
    "现在的问题是，一个不懂计算机的用户，需要搜索电影，怎么办？他不会下载数据，也不会运行上面的代码。这是大部分用户的现状。解决办法是把我们算好的 `movie_embedding` 存在云端。\n",
    "\n",
    "我首先想到的一个办法是把我们的电影原始数据以及我们得到的向量表示 (Embedding) 储存在 MongoDB。然后，在一个 Web App (网页应用程序，你可以理解为一个网站) 上，把这个数据和向量表示下载下来，然后根据用户的搜索，给出最相似的电影推荐。这个办法可行，但是很慢。\n",
    "\n",
    "更好的办法是使用专门用来做向量搜索的数据库。这些向量库有自己的储存和搜索方法，我们不需要用上面的 FAISS。只需要把所有的 embedding 存入。搜索的时候，给一个向量，这些向量库会进行优化搜素，快速给出结果。\n",
    "\n",
    "### Qdrant\n",
    "\n",
    "我先试了一下 [Qdrant](https://qdrant.tech/)。\n",
    "\n",
    "免费版暂时够用了。\n",
    "\n",
    "首先需要运行：\n",
    "\n",
    "```sh\n",
    "pip install qdrant-client\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "# `pip install python-dotenv` first\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "url = os.getenv(\"QDRANT_MOVIE\")\n",
    "api_key = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted existing collection\n",
      "Uploaded batch 1/11\n",
      "Uploaded batch 2/11\n",
      "Uploaded batch 3/11\n",
      "Uploaded batch 4/11\n",
      "Uploaded batch 5/11\n",
      "Uploaded batch 6/11\n",
      "Uploaded batch 7/11\n",
      "Uploaded batch 8/11\n",
      "Uploaded batch 9/11\n",
      "Uploaded batch 10/11\n",
      "Uploaded batch 11/11\n"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "import uuid\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=url,\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "try:\n",
    "    qdrant_client.delete_collection(collection_name='movies')\n",
    "    print(\"Deleted existing collection\")\n",
    "except Exception as e:\n",
    "    print(f\"Collection might not exist yet: {e}\")\n",
    "\n",
    "# Create the collection first\n",
    "vector_size = len(next(iter(movie_embeddings.values())))\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=\"movies\",\n",
    "    vectors_config=VectorParams(\n",
    "        size=vector_size,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "points = []\n",
    "for movie_id in movie_ids:\n",
    "    # Generate a UUID for each movie ID\n",
    "    point_id = str(uuid.uuid4()) #generates a random unique uuid.\n",
    "    points.append({\n",
    "        'id': point_id,\n",
    "        'vector': movie_embeddings[movie_id].tolist(),\n",
    "        'payload': {\n",
    "            'title': imbdId2Title[movie_id],\n",
    "            'overview': imbdId2Overview[movie_id],\n",
    "            'imdb_id': movie_id,\n",
    "        }\n",
    "    })\n",
    "\n",
    "batch_size = 1_000\n",
    "for i in range(0, len(points), batch_size):\n",
    "    batch = points[i:i+batch_size]\n",
    "    qdrant_client.upsert(\n",
    "        collection_name = 'movies',\n",
    "        points = batch\n",
    "    )\n",
    "    print(f\"Uploaded batch {i//batch_size + 1}/{(len(points)-1)//batch_size + 1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_qdrant(\n",
    "    query_text:str, model:SentenceTransformer, top_k:int = 5):\n",
    "    query_embedding = model.encode([query_text])\n",
    "    normalized_query = normalize(query_embedding, axis = 1, norm='l2')\n",
    "\n",
    "    results = qdrant_client.search(\n",
    "        collection_name = 'movies',\n",
    "        query_vector=normalized_query[0].tolist(),\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "    movies = []\n",
    "    for result in results:\n",
    "        movies.append({\n",
    "            'title': result.payload['title'],\n",
    "            'overview': result.payload['overview'],\n",
    "            'imdb_id': result.payload['imdb_id'],\n",
    "            'similarity_score': result.score\n",
    "        })\n",
    "    return movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Mission to Mars',\n",
       "  'overview': 'When contact is lost with the crew of the first Mars expedition, a rescue mission is launched to discover their fate.',\n",
       "  'imdb_id': 'tt0183523',\n",
       "  'similarity_score': 0.6767248},\n",
       " {'title': 'Red Planet',\n",
       "  'overview': 'Astronauts search for solutions to save a dying Earth by searching on Mars, only to have the mission go terribly awry.',\n",
       "  'imdb_id': 'tt0199753',\n",
       "  'similarity_score': 0.6620594},\n",
       " {'title': 'Robinson Crusoe on Mars',\n",
       "  'overview': 'Stranded on Mars with only a monkey as a companion, an astronaut must figure out how to find oxygen, water, and food on the lifeless planet.',\n",
       "  'imdb_id': 'tt0058530',\n",
       "  'similarity_score': 0.651513},\n",
       " {'title': 'The Martian',\n",
       "  'overview': 'During a manned mission to Mars, Astronaut Mark Watney is presumed dead after a fierce storm and left behind by his crew. But Watney has survived and finds himself stranded and alone on the hostile planet. With only meager supplies, he must draw upon his ingenuity, wit and spirit to subsist and find a way to signal to Earth that he is alive.',\n",
       "  'imdb_id': 'tt3659388',\n",
       "  'similarity_score': 0.55047977},\n",
       " {'title': 'Capricorn One',\n",
       "  'overview': 'In order to protect the reputation of the American space program, a team of scientists stages a phony Mars landing. Willingly participating in the deception are a trio of well-meaning astronauts, who become liabilities when their space capsule is reported lost on re-entry. Now, with the help of a crusading reporter,they must battle a sinister conspiracy that will stop at nothing to keep the truth',\n",
       "  'imdb_id': 'tt0077294',\n",
       "  'similarity_score': 0.5192548}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"NASA tried to rescue an astronaut stranded on Mars.\"\n",
    "search_qdrant(query_text=user_query, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinecone\n",
    "\n",
    "也可以用 [Pinecone](https://www.pinecone.io/)。\n",
    "\n",
    "First \n",
    "\n",
    "```bash\n",
    "pip install pinecone\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting existing index: movies!\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "\n",
    "index_name = \"movies\"\n",
    "\n",
    "# Get the list of index names from the dictionaries\n",
    "existing_indexes = [index[\"name\"] for index in pc.list_indexes()]\n",
    "\n",
    "if index_name in existing_indexes:\n",
    "    print(f\"Deleting existing index: {index_name}!\")\n",
    "    pc.delete_index(index_name)\n",
    "else:\n",
    "    print(f\"Index '{index_name}' does not exist.\")\n",
    "\n",
    "vector_size = len(next(iter(movie_embeddings.values())))\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=vector_size, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded batch 1/11\n",
      "Uploaded batch 2/11\n",
      "Uploaded batch 3/11\n",
      "Uploaded batch 4/11\n",
      "Uploaded batch 5/11\n",
      "Uploaded batch 6/11\n",
      "Uploaded batch 7/11\n",
      "Uploaded batch 8/11\n",
      "Uploaded batch 9/11\n",
      "Uploaded batch 10/11\n",
      "Uploaded batch 11/11\n"
     ]
    }
   ],
   "source": [
    "# Get the index object\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "batch_size = 1_000\n",
    "for i in range(0, len(movie_ids), batch_size):\n",
    "    batch_ids = movie_ids[i:i+batch_size]\n",
    "    batch_vectors = []\n",
    "    for movie_id in batch_ids:\n",
    "        batch_vectors.append({\n",
    "            'id': str(movie_id),\n",
    "            'values': movie_embeddings[movie_id].tolist(),\n",
    "            'metadata':{\n",
    "                'title': imbdId2Title.get(movie_id, ''),\n",
    "                'overview': imbdId2Overview.get(movie_id, \"\")\n",
    "            }\n",
    "        })\n",
    "    index.upsert(vectors = batch_vectors)\n",
    "    print(f\"Uploaded batch {i//batch_size + 1}/{(len(movie_ids)-1)//batch_size + 1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pinecone(\n",
    "    query_text:str, \n",
    "    model:SentenceTransformer, \n",
    "    top_k:int = 5):\n",
    "    query_embedding = model.encode([query_text])\n",
    "    normalized_query = normalize(query_embedding, axis = 1, norm='l2')\n",
    "\n",
    "    results = index.query(\n",
    "        vector=normalized_query[0].tolist(),\n",
    "        top_k=top_k,\n",
    "        include_metadata=True\n",
    "    )\n",
    "\n",
    "    # Format results\n",
    "    movies = []\n",
    "    for match in results['matches']:\n",
    "        movies.append({\n",
    "            \"title\": match['metadata']['title'],\n",
    "            \"overview\": match['metadata']['overview'],\n",
    "            \"imdb_id\": match['id'],\n",
    "            \"similarity_score\": match['score']\n",
    "        })\n",
    "    \n",
    "    return movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Mission to Mars',\n",
       "  'overview': 'When contact is lost with the crew of the first Mars expedition, a rescue mission is launched to discover their fate.',\n",
       "  'imdb_id': 'tt0183523',\n",
       "  'similarity_score': 0.676724792},\n",
       " {'title': 'Red Planet',\n",
       "  'overview': 'Astronauts search for solutions to save a dying Earth by searching on Mars, only to have the mission go terribly awry.',\n",
       "  'imdb_id': 'tt0199753',\n",
       "  'similarity_score': 0.662059426},\n",
       " {'title': 'Robinson Crusoe on Mars',\n",
       "  'overview': 'Stranded on Mars with only a monkey as a companion, an astronaut must figure out how to find oxygen, water, and food on the lifeless planet.',\n",
       "  'imdb_id': 'tt0058530',\n",
       "  'similarity_score': 0.651513},\n",
       " {'title': 'The Martian',\n",
       "  'overview': 'During a manned mission to Mars, Astronaut Mark Watney is presumed dead after a fierce storm and left behind by his crew. But Watney has survived and finds himself stranded and alone on the hostile planet. With only meager supplies, he must draw upon his ingenuity, wit and spirit to subsist and find a way to signal to Earth that he is alive.',\n",
       "  'imdb_id': 'tt3659388',\n",
       "  'similarity_score': 0.55047977},\n",
       " {'title': 'Capricorn One',\n",
       "  'overview': 'In order to protect the reputation of the American space program, a team of scientists stages a phony Mars landing. Willingly participating in the deception are a trio of well-meaning astronauts, who become liabilities when their space capsule is reported lost on re-entry. Now, with the help of a crusading reporter,they must battle a sinister conspiracy that will stop at nothing to keep the truth',\n",
       "  'imdb_id': 'tt0077294',\n",
       "  'similarity_score': 0.519254804}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"NASA tried to rescue an astronaut stranded on Mars.\"\n",
    "search_pinecone(query_text=user_query, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 其他选择\n",
    "\n",
    "- [Chroma](https://www.trychroma.com/) 看上去也不错，但是需要 self-host，比较麻烦。\n",
    "- [Azure Cosmos DB](https://learn.microsoft.com/en-us/azure/cosmos-db/vector-database)\n",
    "- [Milvus](https://milvus.io/) 和 [zilliz](https://zilliz.com/pricing) 一起。\n",
    "\n",
    "## 构建 API\n",
    "\n",
    "现在的问题是，我们依然是用代码才能做这些事情。而真正的用户大部分是不懂代码的。我们如何让他们直接输入搜索文本，然后给他们返回结果？这就需要用到 API。也就是说，把搜索文本向量化、搜索、返回搜索结果，都在网络上完成。\n",
    "\n",
    "我用 [FastAPI](/cn/2024/09/01/fastapi/) 做了一个 API。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|code-fold:true\n",
    "\n",
    "from fastapi import FastAPI, HTTPException, Query\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from qdrant_client import QdrantClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize FastAPI app\n",
    "app = FastAPI(\n",
    "    title=\"Movie Search API\",\n",
    "    description=\"Search for movies using semantic similarity\",\n",
    "    version=\"1.0.0\"\n",
    ")\n",
    "\n",
    "# Add CORS middleware to allow cross-origin requests (important for web clients)\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],  # Allows all origins\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],  # Allows all methods\n",
    "    allow_headers=[\"*\"],  # Allows all headers\n",
    ")\n",
    "\n",
    "# Initialize Qdrant client\n",
    "qdrant_url = os.getenv(\"QDRANT_MOVIE\")\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "qdrant_client = QdrantClient(\n",
    "    url=qdrant_url,\n",
    "    api_key=qdrant_api_key\n",
    ")\n",
    "\n",
    "# Initialize the SentenceTransformer model (load it only once at startup)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define response model for better documentation and type checking\n",
    "class MovieSearchResult(BaseModel):\n",
    "    title: str\n",
    "    overview: str\n",
    "    imdb_id: str\n",
    "    similarity_score: float\n",
    "\n",
    "class SearchResponse(BaseModel):\n",
    "    movies: List[MovieSearchResult]\n",
    "    query: str\n",
    "\n",
    "@app.get(\"/\")\n",
    "async def root():\n",
    "    return {\n",
    "        \"message\": \"Welcome to Movie Search API!\",\n",
    "        \"docs\": \"/docs\",\n",
    "        \"usage\": \"Send GET requests to /search?query=your search text\"\n",
    "    }\n",
    "\n",
    "@app.get(\"/search\", response_model=SearchResponse)\n",
    "async def search_movies(\n",
    "    query: str = Query(..., description=\"The search query to find similar movies\"),\n",
    "    top_k: int = Query(5, ge=1, le=50, description=\"Number of results to return\")\n",
    "):\n",
    "    try:\n",
    "        # Encode the query text\n",
    "        query_embedding = model.encode([query])\n",
    "        normalized_query = normalize(query_embedding, axis=1, norm='l2')\n",
    "        \n",
    "        # Search in Qdrant\n",
    "        results = qdrant_client.search(\n",
    "            collection_name='movies',\n",
    "            query_vector=normalized_query[0].tolist(),\n",
    "            limit=top_k\n",
    "        )\n",
    "        \n",
    "        # Format the results\n",
    "        movies = []\n",
    "        for result in results:\n",
    "            movies.append(MovieSearchResult(\n",
    "                title=result.payload['title'],\n",
    "                overview=result.payload['overview'],\n",
    "                imdb_id=result.payload['imdb_id'],\n",
    "                similarity_score=result.score\n",
    "            ))\n",
    "        \n",
    "        return SearchResponse(\n",
    "            movies=movies,\n",
    "            query=query\n",
    "        )\n",
    "    \n",
    "    except Exception as e:\n",
    "        # Log the error (you might want to use a proper logging system)\n",
    "        print(f\"Error during search: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"Search failed: {str(e)}\")\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint to verify the service is running\"\"\"\n",
    "    return {\"status\": \"healthy\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本地运行没问题：\n",
    "\n",
    "{{< figure src=\"/media/cnblog/movie_api_search1.png\" title=\"本地运行 FastAPI\">}}\n",
    "\n",
    "{{< figure src=\"/media/cnblog/movie_api_search2.png\" title=\"本地运行 FastAPI\">}}\n",
    "\n",
    "但是部署到 Vercel 没成功：\n",
    "\n",
    "{{< figure src=\"/media/cnblog/movie_api_search3.png\" title=\"Vercel 部署 FastAPI 失败\">}}\n",
    "\n",
    "这是因为我们需要的包太多了\n",
    "\n",
    "```txt\n",
    "fastapi[all]\n",
    "sentence_transformers\n",
    "qdrant_client\n",
    "python-dotenv==1.0.0\n",
    "scikit-learn==1.3.2\n",
    "```\n",
    "\n",
    "超过了 Vercel 允许的大小限制。\n",
    "\n",
    "最好的办法是找一个适合 ML/LLM 项目的部署平台。我试过免费的 render.com 但是太慢了，因为有休眠限制。\n",
    "\n",
    "第一个解决办法是用封装好的 embedding，比如 DeepSeek OpenAI Gemini 等，这样就不需要 `sentence_transformer` 这么大的包。按道理就可以部署到 Vercel。\n",
    "\n",
    "第二个解决办法是使用专业的 API 部署平台，比如 Google Cloud Platform, Azure, AWS 或者小公司，比如 fly.io, railway.app, heroku.com 等。\n",
    "\n",
    "我之后试试。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
