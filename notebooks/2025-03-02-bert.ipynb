{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "title: \"Bert 模型、向量表示与搜索\"\n",
    "date: 2025-03-02\n",
    "author: 郝鸿涛\n",
    "slug: bert\n",
    "draft: false\n",
    "toc: true\n",
    "tags: ML\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设我们现在有一万个电影的文字描述，如何根据用户的搜索，推荐给用户最相关的几个电影？比如，用户输入「NASA 努力救一个困在火星的宇航员」，那我们肯定会导出《火星救援》。如何实现呢？\n",
    "\n",
    "办法是，假设我们有一个神奇的工具，你可以把它想象成一张网。任何一串文字通过它之后，都会变成一个高维空间里的一个向量，也就是高维空间里的一个坐标。然后我们让这一万条电影的文字描述经过这张网，我们得到一万个坐标。用户输入搜索，我们让这个搜索也经过这张网，得到一个坐标。最后的结果，我们计算这个搜索对应的坐标与每一个电影坐标的余弦相似度 (Cosine Similarity)，然后找到结果最大的几个，就是我们的搜索结果。\n",
    "\n",
    "这张神奇的网是「向量表示 (Embedding)」。我们这里用 Bert。更神奇的是，如果我们用多语言的模型，比如 `paraphrase-multilingual-mpnet-base-v2`，那即使我们的训练数据是英文的，我们也可以用中文搜索。\n",
    "\n",
    "多语言模型比较大，我们这里不用。我们用比较小的 `all-MiniLM-L6-v2`。\n",
    "\n",
    "另外，我们用 [FAISS](https://pypi.org/project/faiss-cpu/) (Facebook AI Similarity Search) 计算余弦相似度，因为这比较快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始数据\n",
    "\n",
    "数据下载地址：[https://hongtaoh.com/files/tmdb-movies.csv](/../files/tmdb-movies.csv)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10866, 21)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../static/files/tmdb-movies.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "imbdId2Title = dict(zip(df.imdb_id, df.original_title))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据很大，我只选取几个关键的列："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>revenue</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135397</td>\n",
       "      <td>tt0369610</td>\n",
       "      <td>1513528810</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>Twenty-two years after the events of Jurassic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76341</td>\n",
       "      <td>tt1392190</td>\n",
       "      <td>378436354</td>\n",
       "      <td>Mad Max: Fury Road</td>\n",
       "      <td>An apocalyptic story set in the furthest reach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>262500</td>\n",
       "      <td>tt2908446</td>\n",
       "      <td>295238201</td>\n",
       "      <td>Insurgent</td>\n",
       "      <td>Beatrice Prior must confront her inner demons ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140607</td>\n",
       "      <td>tt2488496</td>\n",
       "      <td>2068178225</td>\n",
       "      <td>Star Wars: The Force Awakens</td>\n",
       "      <td>Thirty years after defeating the Galactic Empi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>168259</td>\n",
       "      <td>tt2820852</td>\n",
       "      <td>1506249360</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>Deckard Shaw seeks revenge against Dominic Tor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    imdb_id     revenue                original_title  \\\n",
       "0  135397  tt0369610  1513528810                Jurassic World   \n",
       "1   76341  tt1392190   378436354            Mad Max: Fury Road   \n",
       "2  262500  tt2908446   295238201                     Insurgent   \n",
       "3  140607  tt2488496  2068178225  Star Wars: The Force Awakens   \n",
       "4  168259  tt2820852  1506249360                     Furious 7   \n",
       "\n",
       "                                            overview  \n",
       "0  Twenty-two years after the events of Jurassic ...  \n",
       "1  An apocalyptic story set in the furthest reach...  \n",
       "2  Beatrice Prior must confront her inner demons ...  \n",
       "3  Thirty years after defeating the Galactic Empi...  \n",
       "4  Deckard Shaw seeks revenge against Dominic Tor...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:5, [0, 1, 4, 5, 11]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我们只需要用到这两列\n",
    "movie_ids = df.imdb_id.tolist()\n",
    "movie_overviews = df.overview.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 向量表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "from typing import List, Dict, Tuple\n",
    "import faiss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_embeddings(\n",
    "    movie_ids:List[str], \n",
    "    movie_overviews:List[str], \n",
    "    model: SentenceTransformer,\n",
    "    batch_size: int = 32, \n",
    "    ) -> Dict[str, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Generates normalized embeddings for movie overviews.\n",
    "\n",
    "    Args:\n",
    "        movie_ids: List of movie IDs.\n",
    "        movie_overviews: List of movie overviews.\n",
    "        model: Embedding model (e.g., SentenceTransformer).\n",
    "        batch_size: Batch size for processing.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping movie IDs to normalized embeddings.\n",
    "    \"\"\"\n",
    "    if len(movie_ids) != len(movie_overviews):\n",
    "        raise ValueError(\"movie_ids and movie_overviews must have the same length.\")\n",
    "\n",
    "    all_embeddings = []\n",
    "    for i in range(0, len(movie_ids), batch_size):\n",
    "        batch_movies = movie_overviews[i:i+batch_size]\n",
    "        try:\n",
    "            batch_embeddings = model.encode(batch_movies)\n",
    "            all_embeddings.extend(batch_embeddings)\n",
    "        except Exception as e:\n",
    "            print(f\"Error encoding batch {i}: {e}\")\n",
    "            raise\n",
    "    try:\n",
    "        all_embeddings_np = np.array(all_embeddings) #added numpy array conversion.\n",
    "        normalized_embeddings = normalize(all_embeddings_np, axis=1, norm='l2')\n",
    "    except Exception as e:\n",
    "        print(f\"Error normalizing embeddings: {e}\")\n",
    "        raise\n",
    "\n",
    "    movie_embeddings = dict(zip(movie_ids, normalized_embeddings))\n",
    "    return movie_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embeddings = get_movie_embeddings(movie_ids, movie_overviews, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_movies(\n",
    "    movie_embeddings: Dict[str, np.ndarray],\n",
    "    user_query: str,\n",
    "    model: SentenceTransformer,\n",
    "    k: int = 10,\n",
    ") -> Tuple[List[str], List[float]]:\n",
    "    \"\"\"\n",
    "    Searches movies based on a user query using Faiss and cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        movie_embeddings: Dictionary of movie IDs to normalized embeddings.\n",
    "        user_query: The user's search query.\n",
    "        model: SentenceTransformer model.\n",
    "        k: Number of results to return.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples, where each tuple contains (movie_id, similarity_score).\n",
    "    \"\"\"\n",
    "    #prepare faiss index\n",
    "    # Creates a 2D NumPy array\n",
    "    embeddings = np.array(list(movie_embeddings.values())) \n",
    "     # Gets the correct shape\n",
    "    dim = embeddings.shape[1]                            \n",
    "    index = faiss.IndexFlatIP(dim)\n",
    "    index.add(embeddings)\n",
    "\n",
    "    #embed and normalize the user query\n",
    "    query_embedding = model.encode([user_query])\n",
    "    normalized_query_embedding = normalize(query_embedding, axis = 1, norm = 'l2')\n",
    "\n",
    "    #search the index\n",
    "    distances, indices = index.search(normalized_query_embedding, k)\n",
    "\n",
    "    #retrieve movie ids and similarity scores\n",
    "    top_k_ids = [list(movie_embeddings.keys())[i] for i in indices[0]]\n",
    "    top_k_titles = [imbdId2Title[x] for x in top_k_ids]\n",
    "    top_k_scores = distances[0]\n",
    "    return top_k_titles, top_k_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"NASA tried to rescue an astronaut stranded on Mars.\"\n",
    "results = search_movies(\n",
    "    movie_embeddings,\n",
    "    user_query,\n",
    "    model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mission to Mars',\n",
       "  'Red Planet',\n",
       "  'Robinson Crusoe on Mars',\n",
       "  'The Martian',\n",
       "  'Capricorn One',\n",
       "  'My Favorite Martian',\n",
       "  'The Last Days on Mars',\n",
       "  'Infini',\n",
       "  '(T)Raumschiff Surprise - Periode 1',\n",
       "  'My Stepmother is an Alien'],\n",
       " array([0.6767248 , 0.6620594 , 0.651513  , 0.55047977, 0.5192548 ,\n",
       "        0.49691725, 0.4924257 , 0.46683484, 0.46024293, 0.44739133],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果正确。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
